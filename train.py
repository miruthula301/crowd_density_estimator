#!/usr/bin/env python
# coding: utf-8

# # Welcome to Jupyter!

# In[ ]:


import numpy as np
import pdb
import os
import matplotlib.pyplot as plt
from generator import ImageDataGenerator
from model import buildModel_U_net
from keras import backend as K
from keras.callbacks import ModelCheckpoint,Callback,LearningRateScheduler
from scipy import misc
import scipy.ndimage as ndimage

class LossHistory(Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))

base_path = 'cells/'
data = []
meso= []

def step_decay(epoch):
    step = 12
    num =  epoch // step 
    if num % 3 == 0:
        lrate = 1e-5
    elif num % 3 == 1:
        lrate = 1e-6
    else:
        lrate = 1e-7
    print('Learning rate for epoch {} is {}.'.format(epoch+1, lrate))
    return np.float(lrate)
    
def read_data(base_path):
    imList = os.listdir(base_path)
    for i in range(len(imList)): 
        if 'cell' in imList[i]:
            image1 = misc.imread(os.path.join(base_path,imList[i]))
            data.append(img1)   
            image2_ = misc.imread(os.path.join(base_path, imList[i][:3] + 'some.png'))
            image2 = 100.0 * (img2_[:,:,0] > 0)
            image2 = ndimage.gaussian_filter(img2, sigma=(1, 1), order=0)
            anno.append(image2)
    return np.asarray(data, dtype = 'float32'), np.asarray(meso, dtype = 'float32')
    
def train_(base_path):
    data, meso = read_data(base_path)
    meso = np.expand_dims(meso, axis = -1)
    
    mean = np.mean(data)
    std = np.std(data)
    
    data_ = (data - mean) / std
    
    train_data = data_[:150]
    train_meso = meso[:150]

    val_data = data_[150:]
    val_meso = meso[150:]
    
    print('-'*30)
    print('Creating and compiling the fully convolutional regression networks.')
    print('-'*30)    
   
    model = buildModel_U_net(input_dim = (256,256,3))
    model_checkpoint = ModelCheckpoint('crowd_density_estimator.hdf5', monitor='loss', save_best_only=True)
    model.summary()
    change_lr = LearningRateScheduler(step_decay)

    datagen = ImageDataGenerator(
        featurewise_center = 0, 
        samplewise_center = 0,  
        featurewise_std_normalization = train_data / 12,  
        samplewise_std_normalization = train_data.shape[0] / 12,  
        zca_whitening = True,  
        rotation_range = 45,  
        width_shift_range = 0.5,  
        height_shift_range = 0.5,  
        zoom_range = 0.5,
        shear_range = 0.5,
        horizontal_flip = True,  
        vertical_flip = True, 
        fill_mode = 'constant',
        dim_ordering = 'tf')  

    # Fit the model on the batches generated by datagen.flow().
    model.fit_generator(datagen.flow(train_data,
                                     train_meso,
                                     batch_size = 12
                                     ),
                        samples_per_epoch = train_data.shape[0],
                        nb_epoch = 216,
                        callbacks = [model_checkpoint, change_lr],
                       )
    
    A = model.predict(val_data)
    mean_diff = np.average(np.abs(np.sum(np.sum(A,1),1)-np.sum(np.sum(val_anno,1),1))) / (100.0)
    print('After training, the difference is : {} cells per image.'.format(np.abs(mean_diff)))
    
if __name__ == '__main__':
    train_(base_path)

